{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Rule based Scoring using the NER model trained using Spacy"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import spacy\n",
    "from tika import parser\n",
    "import re"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "source": [
    "ner_model = spacy.load(os.path.join(os.path.dirname(os.getcwd()),\"Training_NER/saved-NER.model\"))"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Taking a test resume and the JD of Borneo for testing out the scoring"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "source": [
    "parser_jd = parser.from_file(\"borneo-JD.txt\")\n",
    "parser_resume = parser.from_file(os.path.join(os.path.dirname(os.getcwd()),\n",
    "\"Training_NER/dataset/test/chenna kesava.docx\"))\n",
    "\n",
    "jd = parser_jd[\"content\"]\n",
    "resume = parser_resume[\"content\"]"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Resume Scoring routine"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "source": [
    "def preprocess(doc):\n",
    "    doc = doc.replace(\"\\n\", \" \")\n",
    "    doc = doc.replace(\"•\",\"\")\n",
    "#     doc = doc.replace(\"\")\n",
    "    doc = doc.replace(\"–\",\"\")\n",
    "    doc = doc.replace(\"\\t\",\" \")\n",
    "    doc = doc.strip()\n",
    "    return doc\n",
    "\n",
    "jd = preprocess(jd)\n",
    "resume = preprocess(resume)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "source": [
    "deg_score = 0\n",
    "\n",
    "for word in resume.split(\" \"):\n",
    "    if word.strip() in [\"PhD\",\"PHD\",\"Research Associate\"]:\n",
    "        deg_score=3\n",
    "    elif word.strip() in [\"MS\",\"MT\",\"M.Tech\",\"Masters\"]:\n",
    "        if deg_score<2:\n",
    "            deg_score=2\n",
    "    elif word.strip() in [\"BS\",\"BE\",\"B.S\",\"B.E\",\"B.Tech\",\"Bachelors\"]:\n",
    "        if deg_score<1:\n",
    "            deg_score=1\n",
    "\n",
    "# print(deg_score)        "
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "source": [
    "des_score = 0\n",
    "\n",
    "for word in resume.split(\" \"):\n",
    "    if word.strip() in [\"Sr.\",\"Senior\"]:\n",
    "        if des_score<3:\n",
    "            des_score=3\n",
    "    elif word.strip() in [\"Associate\", \"Scientist\", \"Engineer\"]:\n",
    "        if des_score<2:\n",
    "            des_score=2\n",
    "    elif word.strip() in [\"Analyst\", \"Junior\"]:\n",
    "        if des_score<1:\n",
    "            des_score=1\n",
    "\n",
    "# print(des_score)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "source": [
    "exp_score = 0\n",
    "a = re.findall(r'[0-9]+\\+*[ ]?[Yy]ear',resume)\n",
    "a.sort()\n",
    "\n",
    "if len(a)>0:\n",
    "    exp = a[len(a)-1].lower().split(\"y\")[0].strip()\n",
    "#     print(exp)\n",
    "\n",
    "    if \"+\" in exp :\n",
    "        exp = exp[:-1]\n",
    "    \n",
    "    exp = int(exp)\n",
    "#     print(exp)\n",
    "    if exp>=4:\n",
    "        exp_score=3\n",
    "    elif exp>=2:\n",
    "        exp_score=2\n",
    "    elif exp==1:\n",
    "        exp_score=1"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Cosine Document Similarity for comparing resume and skills with the JD"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "source": [
    "import math\n",
    "import string\n",
    "import sys\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "nltk.download('stopwords')\n",
    "\n",
    "\n",
    "# splitting the text lines into words\n",
    "# translation table is a global variable\n",
    "# mapping upper case to lower case and\n",
    "# punctuation to spaces\n",
    "translation_table = str.maketrans(string.punctuation+string.ascii_uppercase,\n",
    "\t\t\t\t\t\t\t\t\t\" \"*len(string.punctuation)+string.ascii_lowercase)\n",
    "\t\n",
    "# returns a list of the words\n",
    "# in the file\n",
    "def get_words_from_line_list(text):\n",
    "\t\n",
    "\ttext = text.translate(translation_table)\n",
    "\tword_list = [x for x in text.split() if x not in set(stopwords.words('english'))]\n",
    "\t\n",
    "\treturn word_list\n",
    "\n",
    "\n",
    "# counts frequency of each word\n",
    "# returns a dictionary which maps\n",
    "# the words to their frequency.\n",
    "def count_frequency(word_list):\n",
    "\t\n",
    "\tD = {}\n",
    "\t\n",
    "\tfor new_word in word_list:\n",
    "\t\t\n",
    "\t\tif new_word in D:\n",
    "\t\t\tD[new_word] = D[new_word] + 1\n",
    "\t\t\t\n",
    "\t\telse:\n",
    "\t\t\tD[new_word] = 1\n",
    "\t\t\t\n",
    "\treturn D\n",
    "\n",
    "# returns dictionary of (word, frequency)\n",
    "# pairs from the previous dictionary.\n",
    "def word_frequencies_for_text(text):\n",
    "\t\n",
    "\tline_list = text\n",
    "\tword_list = get_words_from_line_list(line_list)\n",
    "\tfreq_mapping = count_frequency(word_list)\n",
    "\n",
    "# \tprint(\"File\", filename, \":\", )\n",
    "# \tprint(len(line_list), \"lines, \", )\n",
    "# \tprint(len(word_list), \"words, \", )\n",
    "# \tprint(len(freq_mapping), \"distinct words\")\n",
    "\n",
    "\treturn freq_mapping\n",
    "\n",
    "\n",
    "# returns the dot product of two documents\n",
    "def dotProduct(D1, D2):\n",
    "\tSum = 0.0\n",
    "\t\n",
    "\tfor key in D1:\n",
    "\t\t\n",
    "\t\tif key in D2:\n",
    "\t\t\tSum += (D1[key] * D2[key])\n",
    "\t\t\t\n",
    "\treturn Sum\n",
    "\n",
    "# returns the angle in radians\n",
    "# between document vectors\n",
    "def vector_angle(D1, D2):\n",
    "\tnumerator = dotProduct(D1, D2)\n",
    "\tdenominator = math.sqrt(dotProduct(D1, D1)*dotProduct(D2, D2))\n",
    "\t\n",
    "\treturn math.acos(numerator / denominator)\n",
    "\n",
    "\n",
    "def documentSimilarity(text_1, text_2):\n",
    "    sorted_word_list_1 = word_frequencies_for_text(text_1)\n",
    "    sorted_word_list_2 = word_frequencies_for_text(text_2)\n",
    "    distance = vector_angle(sorted_word_list_1, sorted_word_list_2)\n",
    "    return math.degrees(distance)\n",
    "\t\n",
    "# Driver code\n",
    "# documentSimilarity(jd, resume)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /Users/abhinaykumar/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "source": [
    "doc = ner_model(resume)\n",
    "\n",
    "skill_list = [tok.text for tok in doc if tok.ent_type_==\"Skills\"]\n",
    "skill_text = \" \".join(skill_list)\n",
    "\n",
    "skill_score = 0\n",
    "\n",
    "if len(skill_list)>0:\n",
    "    skill_match = 90.0-documentSimilarity(jd,skill_text)\n",
    "    ## Skills are matched on a scale of 0-10\n",
    "    skill_score = min(10,skill_match)\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Overall Resume Match"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "source": [
    "resume_match = 90-documentSimilarity(jd, resume)\n",
    "resume_score = min(20,resume_match)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Resume Score (on scale 1 to 10)"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "source": [
    "score = round(10/7*(deg_score*0.20+des_score*0.20+exp_score*0.20+skill_score*0.30+resume_score*0.10),1)\n",
    "print(score)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "2.8\n"
     ]
    }
   ],
   "metadata": {}
  }
 ],
 "metadata": {
  "orig_nbformat": 4,
  "language_info": {
   "name": "python",
   "version": "3.7.10",
   "mimetype": "text/x-python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "pygments_lexer": "ipython3",
   "nbconvert_exporter": "python",
   "file_extension": ".py"
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.7.10 64-bit ('P37': conda)"
  },
  "interpreter": {
   "hash": "99224b4fe21c86f432616aa70efdc02870888a2e3e57f0b16a586df12b01d760"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}